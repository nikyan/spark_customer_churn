{"nbformat_minor": 1, "cells": [{"source": "# Sparkify Project Pipeline - Full Dataset on GCP Cluster\n\nThis Jupyter Notebook contains the execution script for loading the Sparkify dataset (12GB), extracting features, running machine learning models to predict 'churn' and finally tuning the model to achieve best results.\n\nThis Notebook is run on larger dataset to test and present various concepts on a Spark cluster. Some of the exploration tasks have been trimmed from this Notebook to give a better performance with large dataset.", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "bpYIRqzlN3gU"}}, {"source": "## Import Dependencies & Libraries ", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "jgNGU5BMN3ga"}}, {"execution_count": 1, "cell_type": "code", "source": "# Starter code\nfrom pyspark.sql import SparkSession", "outputs": [], "metadata": {}}, {"execution_count": 2, "cell_type": "code", "source": "# Create spark session\nspark = SparkSession \\\n        .builder \\\n        .appName(\"Sparkify\") \\\n        .getOrCreate()", "outputs": [], "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": "# import libraries\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nimport datetime\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression, GBTClassifier, RandomForestClassifier, DecisionTreeClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler, PCA\nfrom pyspark.ml.feature import Normalizer, MinMaxScaler, StandardScaler\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder", "outputs": [], "metadata": {"colab_type": "code", "id": "8F57y1DaN3gu", "colab": {}}}, {"source": "## Feature Extraction\n\nFollowing are all the functions that are used to extract features from the dataset and make a dataframe ready for machine learning algorithms.", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "dedTlObYN3hC"}}, {"execution_count": 4, "cell_type": "code", "source": "def load_data(filename):\n    \n    '''\n    Funtion to load data and remove null, empty strings.\n    INPUT\n    filename = name of file as well the path\n    OUTPUT\n    df - a spark dataframe with no null rows for primary key\n    '''\n    \n    df = spark.read.json(filename)\n    \n    # remove empty string from userId\n    df = df.filter(df.userId != \"\")\n    \n    print(\"Count of rows in dataframe: {}\".format(df.count()))\n          \n    return df", "outputs": [], "metadata": {"colab_type": "code", "id": "lkbM_iBUN3hD", "colab": {}}}, {"execution_count": 5, "cell_type": "code", "source": "def add_date_columns(df):\n    '''\n    Funtion to add date/time related columns to the dataframe.\n    INPUT - a spark dataframe\n    OUPUT - a spark dataframe with calculated fields: hour, month, year, day\n    '''\n    # create a function to get hour, month, year, day from timestamp\n    get_hour = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0).hour)\n    get_month = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0).month)\n    get_year = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0).year)\n    get_day = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0).day)\n\n    \n    \n    # add hour, month, year, day, date columns to the dataframe\n    df = df.withColumn(\"hour\", get_hour(df.ts))\n    df = df.withColumn(\"month\", get_month(df.ts))\n    df = df.withColumn(\"year\", get_year(df.ts))\n    df = df.withColumn(\"day\", get_day(df.ts))\n    df = df.withColumn(\"date\", from_unixtime(df.ts/1000).cast(DateType()))\n    \n    \n    return df", "outputs": [], "metadata": {"colab_type": "code", "id": "EoblwQ08N3hK", "colab": {}}}, {"execution_count": 6, "cell_type": "code", "source": "def get_flag_churn(df):\n    '''\n    Funtion to add churn flag that identifies whether a user has churned.\n    INPUT - a spark dataframe\n    OUPUT - a spark dataframe with userId of each user, churn flag and gender\n    '''\n    \n    # function to flag 'cancellation confirmation' event\n    flag_cancel_event = udf(lambda x: 1 if x == \"Cancellation Confirmation\" else 0, IntegerType())\n    df = df.withColumn(\"churn\", flag_cancel_event(\"page\"))\n    user_churn = df.groupBy(\"userId\").agg({\"churn\":\"max\", \"gender\":\"max\"})\\\n                           .withColumnRenamed(\"max(churn)\", \"label\")\\\n                           .withColumnRenamed(\"max(gender)\", \"gender\")\n    \n    #print(\"Count of rows: {}\".format(user_churn.count()))\n    return user_churn", "outputs": [], "metadata": {"colab_type": "code", "id": "jRXQBFV5N3hQ", "colab": {}}}, {"execution_count": 7, "cell_type": "code", "source": "def get_latest_level(df):\n    '''\n    Funtion to find the latest level of each user.\n    INPUT - a spark dataframe\n    OUPUT - a spark dataframe with userId of each user and latest level\n    '''\n    # use timestamp to identify the most latest record for a user\n    # sort timestamp in descending order and than drop duplicates to get the last row for each user\n    latest_level = df.select([\"userId\", \"level\", \"ts\"])\\\n                        .orderBy(desc(\"ts\"))\\\n                        .dropDuplicates([\"userId\"])\\\n                        .select([\"userId\", \"level\"])\n    #print(\"Count of rows: {}\".format(latest_level.count()))\n    return latest_level", "outputs": [], "metadata": {"colab_type": "code", "id": "nuQ667asN3hV", "colab": {}}}, {"execution_count": 8, "cell_type": "code", "source": "def get_states(df):\n    '''\n    Funtion to clean location column and return cleaned state names.\n    INPUT - a spark dataframe\n    OUPUT - a spark dataframe with userId of each user and state from location\n    '''\n    # get location of each user\n    state_data = df.groupBy(\"userId\").agg({\"location\":\"max\"}).withColumnRenamed(\"max(location)\", \"state\")\n    # extract state\n    state_data = state_data.withColumn(\"state\", split(col(\"state\"),',').getItem(1))\n    \n    #print(\"Count of rows: {}\".format(state_data.count()))\n    \n    return state_data", "outputs": [], "metadata": {"colab_type": "code", "id": "oNDgrvlZN3ha", "colab": {}}}, {"execution_count": 9, "cell_type": "code", "source": "def get_device(df):\n    '''\n    Funtion to clean userAgent column and return cleaned device/os names.\n    INPUT:\n    df - a spark dataframe\n    OUPUT:\n    device_data - a spark dataframe with userId of each user and device/os name\n    '''\n      \n    device_data = df.groupBy(\"userId\").agg({\"userAgent\":\"max\"}).withColumnRenamed(\"max(userAgent)\", \"device\")\n    device_data = device_data.withColumn(\"device\", regexp_extract(col(\"device\"), r'\\((.*?)\\)', 1));\n    \n    device_data = device_data.withColumn(\"device\", split(col(\"device\"),';').getItem(0))\n    device_data = device_data.withColumn(\"device\", split(col(\"device\"),'NT').getItem(0))\n    \n    device_data = device_data.withColumn(\"device\", trim(device_data.device))\n    \n    #print(\"Count of rows: {}\".format(device_data.count()))\n    \n    return device_data", "outputs": [], "metadata": {"colab_type": "code", "id": "JpZaajOrN3hf", "colab": {}}}, {"execution_count": 10, "cell_type": "code", "source": "def get_days_since_reg(df):\n    '''\n    Funtion to get the number of days since registration\n    INPUT:\n    df - a spark dataframe\n    OUPUT:\n    days_since_reg - a spark dataframe with userId of each user and days since registration\n    '''\n    \n    # replace null in 'registration' or 'ts' field with 0\n    df = df.fillna(0, subset=['registration', 'ts'])\n    \n    get_subtract_ts = udf(lambda x, y: datetime.datetime.fromtimestamp((y - x) / 1000.0).day, IntegerType())\n\n    days_since_reg = df.groupBy(\"userId\").agg({\"registration\":\"max\", \"ts\":\"max\"})\\\n                                         .withColumnRenamed(\"max(registration)\", \"max_reg\")\\\n                                         .withColumnRenamed(\"max(ts)\", \"max_ts\")\n    \n    days_since_reg = days_since_reg.withColumn(\"days_since_reg\", when(col('max_reg') != 0, get_subtract_ts(col('max_reg'), col('max_ts'))).otherwise(0))\n    \n    days_since_reg = days_since_reg.drop(\"max_reg\")\n    days_since_reg = days_since_reg.drop(\"max_ts\")\n    \n    #print(\"Count of rows: {}\".format(days_since_reg.count()))\n    \n    return days_since_reg", "outputs": [], "metadata": {"colab_type": "code", "id": "nR9GUwoXN3hn", "colab": {}}}, {"execution_count": 11, "cell_type": "code", "source": "def get_avg_count_session(df):\n    '''\n    Funtion to get the average number of sessions per month for a user\n    INPUT:\n    df - a spark dataframe\n    OUPUT:\n    avg_count_session - a spark dataframe with userId of each user and average monthly count of sessions\n    '''\n    mon_count_session = df.groupBy(\"userId\", \"month\").agg(countDistinct(\"sessionId\"))\\\n                          .groupBy(\"userId\").agg(avg(\"count(DISTINCT sessionId)\"))\\\n                          .withColumnRenamed(\"avg(count(DISTINCT sessionId))\", \"avg_mon_session_count\")\n    \n    #print(\"Count of rows: {}\".format(mon_count_session.count()))\n    \n    return mon_count_session", "outputs": [], "metadata": {"colab_type": "code", "id": "hZR26o4uN3hv", "colab": {}}}, {"execution_count": 12, "cell_type": "code", "source": "def get_avg_duration_session(df):\n    '''\n    Funtion to get the average number of sessions per month for a user\n    INPUT:\n    df - a spark dataframe\n    OUPUT:\n    avg_duration_session - a spark dataframe with userId of each user and average monthly count of sessions\n    '''\n    \n    mon_sess_duration = df.groupBy(\"userId\", \"month\").agg(max(\"ts\"), min(\"ts\"))\\\n                          .withColumn(\"duration\", (col(\"max(ts)\") - col(\"min(ts)\"))/1000)\\\n                          .groupBy(\"userId\").agg(avg(\"duration\"))\\\n                          .withColumnRenamed(\"avg(duration)\", \"avg_mon_sess_duration\")\n    \n    #print(\"Count of rows: {}\".format(mon_sess_duration.count()))\n    \n    return mon_sess_duration", "outputs": [], "metadata": {"colab_type": "code", "id": "ZSJsQKYWN3h1", "colab": {}}}, {"execution_count": 13, "cell_type": "code", "source": "def get_avg_page_views(df):\n    '''\n    Funtion to get the average number of page views per date and month for a user\n    INPUT:\n    df - a spark dataframe\n    OUPUT:\n    avg_page_views - a spark dataframe with userId of each user and average monthly page views with each page pivoted\n    '''\n    # --------------- Monthly views -----------------:\n    # get avg of page views per month\n    avg_mon_page_views = df.groupBy(\"userId\", \"page\", \"month\").agg(count(\"page\"))\\\n                           .groupBy(\"userId\", \"page\").agg(avg(\"count(page)\"))\\\n                           .withColumnRenamed(\"avg(count(page))\", \"avg_page_count\")\n    \n    # clean up page column\n    avg_mon_page_views = avg_mon_page_views.withColumn(\"page\", trim(avg_mon_page_views.page))\n    avg_mon_page_views = avg_mon_page_views.withColumn(\"page\", regexp_replace(avg_mon_page_views.page, \" \", \"_\"))\n    \n    # add prefix to each page name\n    add_prefix = udf(lambda x: \"avg_mon_\" + x)\n    avg_mon_page_views = avg_mon_page_views.withColumn(\"page\", add_prefix(avg_mon_page_views.page))\n    \n    # pivot page names to get columns\n    avg_mon_page_views = avg_mon_page_views.groupBy(\"userId\").pivot(\"page\").max(\"avg_page_count\")\n    avg_mon_page_views = avg_mon_page_views.fillna(0)\n    \n    # ---------------- Daily views --------------------:\n    # get avg of page views per day\n    avg_daily_page_views = df.groupBy(\"userId\", \"page\", \"date\").agg(count(\"page\"))\\\n                           .groupBy(\"userId\", \"page\").agg(avg(\"count(page)\"))\\\n                           .withColumnRenamed(\"avg(count(page))\", \"avg_daily_page_count\")\n    \n    # clean up page column\n    avg_daily_page_views = avg_daily_page_views.withColumn(\"page\", trim(avg_daily_page_views.page))\n    avg_daily_page_views = avg_daily_page_views.withColumn(\"page\", regexp_replace(avg_daily_page_views.page, \" \", \"_\"))\n    \n    # add prefix to each page name\n    add_prefix_daily = udf(lambda x: \"avg_daily_\" + x)\n    avg_daily_page_views = avg_daily_page_views.withColumn(\"page\", add_prefix_daily(avg_daily_page_views.page))\n    \n    # pivot page names to get columns\n    avg_daily_page_views = avg_daily_page_views.groupBy(\"userId\").pivot(\"page\").max(\"avg_daily_page_count\")\n    avg_daily_page_views = avg_daily_page_views.fillna(0)\n\n    # join daily and monthly views.\n    avg_page_views = avg_daily_page_views.join(avg_mon_page_views, on=\"userId\")\n\n    #print(\"Count of rows: {}\".format(avg_mon_page_views.count()))\n\n    \n    return avg_page_views", "outputs": [], "metadata": {"colab_type": "code", "id": "wWgDdlXkN3h6", "colab": {}}}, {"execution_count": 14, "cell_type": "code", "source": "def extract_features(df):\n    '''\n    Funtion to extract feautres from the log data.\n    INPUT:\n    df - a spark dataframe\n    OUPUT:\n    df - a spark dataframe with userId as set of unique rows and columns with features extracted\n    '''\n\n    # add date columns\n    df = add_date_columns(df)\n\n    # get churn and gender columns\n    user_label = get_flag_churn(df)\n\n    # get latest level of the user\n    latest_level = get_latest_level(df)\n\n    # extract states from location\n    states = get_states(df)\n\n    # extract device/os from userAgent\n    device = get_device(df)\n\n    # get days since registration\n    days_since_reg = get_days_since_reg(df)\n\n    # get average monthly count of sessions per user\n    avg_count_session = get_avg_count_session(df)\n\n    # get average monthly duration of sessions per user\n    avg_duration_session = get_avg_duration_session(df)\n\n    # get average monthly page views per page per user\n    avg_page_views = get_avg_page_views(df)\n\n\n    # join all extracted tables\n    user_data_all = user_label.join(latest_level, on=\"userId\")\\\n                              .join(states, on=\"userId\")\\\n                              .join(device, on=\"userId\")\\\n                              .join(days_since_reg, on=\"userId\")\\\n                              .join(avg_count_session, on=\"userId\")\\\n                              .join(avg_duration_session, on=\"userId\")\\\n                              .join(avg_page_views, on=\"userId\")\n\n    # check count\n    x1 = user_data_all.count()\n    x2 = event_data.select(\"userId\").dropDuplicates().count()\n    if (x1 == x2):\n      print(\"The number of rows in final merged table ({}) matches number of unique users ({}).\".format(x1, x2))\n    else:\n      print(\"The numebr of rows in final merged tables ({}) do not match number of unique users ({}).\".format(x1, x2))\n\n\n    # check for nans and nulls\n    user_data_all.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in user_data_all.columns]).show()\n\n    return user_data_all", "outputs": [], "metadata": {"colab_type": "code", "id": "cTRQMAFnxd82", "colab": {}}}, {"source": "## Modeling", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "-hlO25MMN3iA"}}, {"source": "### Data transformation for ML algorithms", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "MiqgeNpkN3iC"}}, {"execution_count": 15, "cell_type": "code", "source": "def transform_data(df, numerical_col, categorical_col, pca=10):\n    '''\n    Function to transform categorical fields and create features vector. The function uses Pipeline to convert string to numerical, \n    vectorize, standardize and perform PCA.\n    INPUT:\n    df - a spark dataframe\n    numerical_col - a list of numerical columns that should be used in ML models\n    categorical_col - a list of categorical columns that should be used in ML models\n    pca - a number of principal components to retain for ML models. Default value is 10.\n    OUPUT:\n    df - a spark dataframe with transformed data containing features, scaledFeatures and pcaFeatures vector\n    '''\n    \n    # Define stringIndexer for converting categorical to numerical variables\n    # Apply VectorAssembler to create feature vector\n    # Normalize data before performing PCA\n    # Perform PCA for feature selection\n    # Use pipeline to create ML ready data\n    \n\n    # convert categorical columns to numerical\n    stages = []\n    for col in categorical_col:\n        stringIndexer = StringIndexer(inputCol = col, outputCol = col + '_index', handleInvalid = 'keep')\n        #encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[col + \"_classVec\"])\n        #stages += [stringIndexer, encoder]\n        stages += [stringIndexer]\n\n    # vectorize columns\n    assemblerInputs = [c + \"_index\" for c in categorical_col] + numerical_col\n    assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n    stages += [assembler]\n    \n\n    # Rescale feature vector\n    # scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",   withStd=True, withMean=False)\n    scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n    stages += [scaler]\n    \n    pca = PCA(k=pca, inputCol=\"scaledFeatures\", outputCol=\"pcaFeatures\")\n    stages += [pca]\n\n\n    # use pipeline to transform data\n    cols = df.columns\n    pipeline = Pipeline(stages = stages)\n    pipelineModel = pipeline.fit(df)\n    df = pipelineModel.transform(df)\n    \n    #select new 'feature' column and rest of columns\n    selectedCols = ['features', 'scaledFeatures', 'pcaFeatures'] + cols\n    df = df.select(selectedCols)\n\n    return df", "outputs": [], "metadata": {"colab_type": "code", "id": "wcuZTQI4N3iD", "colab": {}}}, {"source": "### Baseline models testing", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "m-P2n2q9N3iJ"}}, {"execution_count": 16, "cell_type": "code", "source": "def model_testing(model, train, test):\n    '''\n    Funtion to test baseline machine learning algorithms\n    INPUT:\n    model - instantiated model object\n    train - training dataset\n    test - testing dataset\n    OUPUT:\n    score - F1 score to measure performance of the algorithm\n    '''\n       \n    cl_model = model.fit(train)\n    predict_train = cl_model.transform(train)\n    predict_test = cl_model.transform(test)\n\n    # Because of imbabalnced dataset, it is preferred to use F1 score as evaluation metric\n    evaluator = MulticlassClassificationEvaluator(metricName='f1')\n    score_train = evaluator.evaluate(predict_train)\n    score_test = evaluator.evaluate(predict_test)\n\n    return score_train, score_test", "outputs": [], "metadata": {"colab_type": "code", "id": "-rO2Vpp6N3iK", "colab": {}}}, {"source": "### Parameter tuning", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "DwFAU71WN3iT"}}, {"execution_count": 11, "cell_type": "code", "source": "def model_tuning(train, test, model, paramGrid, numFolds):\n    '''\n    Funtion to tune a machine learning algorithm using cross validation\n    INPUT:\n    model - instantiated model object\n    paramGrid - hyper parameters associated with the model used for tuning\n    numFolds - number of cross validation folds\n    train - training dataset\n    test - testing dataset\n    \n    OUPUT:\n    score_train - F1 score to measure performance of the algorithm on training dataset\n    score_test - F1 score to measure performance of the algorithm on testing dataset\n    predict_train - dataframe with prediction results from transformation on training dataset\n    predict_test - dataframe with prediction results from transformation on testing dataset\n    bestModel - best model object to get the best parameters from the paramGrid\n    '''\n    \n    # instantiate evaluator with F1 score as metric\n    evaluator = MulticlassClassificationEvaluator(metricName=\"f1\")\n\n    # instantiate cross validation object\n    cv = CrossValidator(estimator=model, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=numFolds)\n    \n    # fit and transform\n    cvmodel = cv.fit(train)\n    predict_train = cvmodel.transform(train)\n    predict_test = cvmodel.transform(test)\n    \n    # get the f1 score\n    score_train = evaluator.evaluate(predict_train)\n    score_test = evaluator.evaluate(predict_test)\n    \n    bestModel = cvmodel.bestModel\n    \n    return score_train, score_test, predict_train, predict_test, bestModel\n    ", "outputs": [], "metadata": {"colab_type": "code", "id": "w79EQDBVN3iU", "colab": {}}}, {"source": "## Execution", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "1xINm7CJN3ia"}}, {"source": "### 1. Load dataset", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "XEa32EC1N3ib"}}, {"execution_count": 18, "cell_type": "code", "source": "# link to mini dataset\npath = \"gs://sparkify-bucket/data/sparkify_event_data.json\"\n\n# load Spark dataframe\nevent_data = load_data(path)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Count of rows in dataframe: 26259199\n"}], "metadata": {"outputId": "7caeef87-2101-430d-e168-675beae1100b", "colab_type": "code", "id": "_BZZIQxxN3ic", "colab": {"base_uri": "https://localhost:8080/", "height": 35}}}, {"execution_count": 19, "cell_type": "code", "source": "# check for nans and nulls\nevent_data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in event_data.columns]).show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-------+----+---------+------+-------------+--------+-------+-----+--------+------+----+------------+---------+-------+------+---+---------+------+\n| artist|auth|firstName|gender|itemInSession|lastName| length|level|location|method|page|registration|sessionId|   song|status| ts|userAgent|userId|\n+-------+----+---------+------+-------------+--------+-------+-----+--------+------+----+------------+---------+-------+------+---+---------+------+\n|5408927|   0|   778479|778479|            0|  778479|5408927|    0|  778479|     0|   0|      778479|        0|5408927|     0|  0|   778479|     0|\n+-------+----+---------+------+-------------+--------+-------+-----+--------+------+----+------------+---------+-------+------+---+---------+------+\n\n"}], "metadata": {"outputId": "dd9299c5-5a1f-4fed-c56e-15904dd154f2", "colab_type": "code", "id": "dAIKzm9HN3im", "colab": {"base_uri": "https://localhost:8080/", "height": 121}}}, {"execution_count": 20, "cell_type": "code", "source": "event_data.printSchema()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- artist: string (nullable = true)\n |-- auth: string (nullable = true)\n |-- firstName: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- itemInSession: long (nullable = true)\n |-- lastName: string (nullable = true)\n |-- length: double (nullable = true)\n |-- level: string (nullable = true)\n |-- location: string (nullable = true)\n |-- method: string (nullable = true)\n |-- page: string (nullable = true)\n |-- registration: long (nullable = true)\n |-- sessionId: long (nullable = true)\n |-- song: string (nullable = true)\n |-- status: long (nullable = true)\n |-- ts: long (nullable = true)\n |-- userAgent: string (nullable = true)\n |-- userId: string (nullable = true)\n\n"}], "metadata": {"outputId": "a4bfb690-6a03-4bfa-e3ab-b2a6b87894c5", "colab_type": "code", "id": "u3ve12M-N3is", "colab": {"base_uri": "https://localhost:8080/", "height": 364}}}, {"source": "### 2. Extract features", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "_4ulixETN3i9"}}, {"execution_count": null, "cell_type": "code", "source": "%%time\nuser_data_all = extract_features(event_data)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "The number of rows in final merged table (22278) matches number of unique users (22278).\n+------+------+-----+-----+-----+------+--------------+---------------------+---------------------+---------------+--------------------+-------------------------+----------------+-----------------------------------+-------------------+---------------+--------------+--------------+---------------+----------------+------------------+------------------+---------------------+-----------------------+------------------+--------------------------+-----------------------------+------------------------+---------------------+-------------------+-----------------+-------------+------------------+-----------------------+--------------+---------------------------------+-----------------+-------------+------------+------------+-------------+--------------+----------------+----------------+-------------------+---------------------+----------------+------------------------+---------------------------+----------------------+-------------------+-----------------+---------------+\n|userId|gender|label|level|state|device|days_since_reg|avg_mon_session_count|avg_mon_sess_duration|avg_daily_About|avg_daily_Add_Friend|avg_daily_Add_to_Playlist|avg_daily_Cancel|avg_daily_Cancellation_Confirmation|avg_daily_Downgrade|avg_daily_Error|avg_daily_Help|avg_daily_Home|avg_daily_Login|avg_daily_Logout|avg_daily_NextSong|avg_daily_Register|avg_daily_Roll_Advert|avg_daily_Save_Settings|avg_daily_Settings|avg_daily_Submit_Downgrade|avg_daily_Submit_Registration|avg_daily_Submit_Upgrade|avg_daily_Thumbs_Down|avg_daily_Thumbs_Up|avg_daily_Upgrade|avg_mon_About|avg_mon_Add_Friend|avg_mon_Add_to_Playlist|avg_mon_Cancel|avg_mon_Cancellation_Confirmation|avg_mon_Downgrade|avg_mon_Error|avg_mon_Help|avg_mon_Home|avg_mon_Login|avg_mon_Logout|avg_mon_NextSong|avg_mon_Register|avg_mon_Roll_Advert|avg_mon_Save_Settings|avg_mon_Settings|avg_mon_Submit_Downgrade|avg_mon_Submit_Registration|avg_mon_Submit_Upgrade|avg_mon_Thumbs_Down|avg_mon_Thumbs_Up|avg_mon_Upgrade|\n+------+------+-----+-----+-----+------+--------------+---------------------+---------------------+---------------+--------------------+-------------------------+----------------+-----------------------------------+-------------------+---------------+--------------+--------------+---------------+----------------+------------------+------------------+---------------------+-----------------------+------------------+--------------------------+-----------------------------+------------------------+---------------------+-------------------+-----------------+-------------+------------------+-----------------------+--------------+---------------------------------+-----------------+-------------+------------+------------+-------------+--------------+----------------+----------------+-------------------+---------------------+----------------+------------------------+---------------------------+----------------------+-------------------+-----------------+---------------+\n|     0|     1|    0|    0|    1|     1|             0|                    0|                    0|              0|                   0|                        0|               0|                                  0|                  0|              0|             0|             0|              0|               0|                 0|                 0|                    0|                      0|                 0|                         0|                            0|                       0|                    0|                  0|                0|            0|                 0|                      0|             0|                                0|                0|            0|           0|           0|            0|             0|               0|               0|                  0|                    0|               0|                       0|                          0|                     0|                  0|                0|              0|\n+------+------+-----+-----+-----+------+--------------+---------------------+---------------------+---------------+--------------------+-------------------------+----------------+-----------------------------------+-------------------+---------------+--------------+--------------+---------------+----------------+------------------+------------------+---------------------+-----------------------+------------------+--------------------------+-----------------------------+------------------------+---------------------+-------------------+-----------------+-------------+------------------+-----------------------+--------------+---------------------------------+-----------------+-------------+------------+------------+-------------+--------------+----------------+----------------+-------------------+---------------------+----------------+------------------------+---------------------------+----------------------+-------------------+-----------------+---------------+\n\nCPU times: user 939 ms, sys: 349 ms, total: 1.29 s\nWall time: 18min 11s\n"}], "metadata": {"outputId": "f2b19fda-f0f6-4137-abbc-5793617e4898", "colab_type": "code", "id": "lQWnFb4I4W8_", "colab": {"base_uri": "https://localhost:8080/", "height": 193}}}, {"execution_count": null, "cell_type": "code", "source": "# check schema for all columns\nuser_data_all.printSchema()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- userId: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- label: integer (nullable = true)\n |-- level: string (nullable = true)\n |-- state: string (nullable = true)\n |-- device: string (nullable = true)\n |-- days_since_reg: integer (nullable = true)\n |-- avg_mon_session_count: double (nullable = true)\n |-- avg_mon_sess_duration: double (nullable = true)\n |-- avg_daily_About: double (nullable = false)\n |-- avg_daily_Add_Friend: double (nullable = false)\n |-- avg_daily_Add_to_Playlist: double (nullable = false)\n |-- avg_daily_Cancel: double (nullable = false)\n |-- avg_daily_Cancellation_Confirmation: double (nullable = false)\n |-- avg_daily_Downgrade: double (nullable = false)\n |-- avg_daily_Error: double (nullable = false)\n |-- avg_daily_Help: double (nullable = false)\n |-- avg_daily_Home: double (nullable = false)\n |-- avg_daily_Login: double (nullable = false)\n |-- avg_daily_Logout: double (nullable = false)\n |-- avg_daily_NextSong: double (nullable = false)\n |-- avg_daily_Register: double (nullable = false)\n |-- avg_daily_Roll_Advert: double (nullable = false)\n |-- avg_daily_Save_Settings: double (nullable = false)\n |-- avg_daily_Settings: double (nullable = false)\n |-- avg_daily_Submit_Downgrade: double (nullable = false)\n |-- avg_daily_Submit_Registration: double (nullable = false)\n |-- avg_daily_Submit_Upgrade: double (nullable = false)\n |-- avg_daily_Thumbs_Down: double (nullable = false)\n |-- avg_daily_Thumbs_Up: double (nullable = false)\n |-- avg_daily_Upgrade: double (nullable = false)\n |-- avg_mon_About: double (nullable = false)\n |-- avg_mon_Add_Friend: double (nullable = false)\n |-- avg_mon_Add_to_Playlist: double (nullable = false)\n |-- avg_mon_Cancel: double (nullable = false)\n |-- avg_mon_Cancellation_Confirmation: double (nullable = false)\n |-- avg_mon_Downgrade: double (nullable = false)\n |-- avg_mon_Error: double (nullable = false)\n |-- avg_mon_Help: double (nullable = false)\n |-- avg_mon_Home: double (nullable = false)\n |-- avg_mon_Login: double (nullable = false)\n |-- avg_mon_Logout: double (nullable = false)\n |-- avg_mon_NextSong: double (nullable = false)\n |-- avg_mon_Register: double (nullable = false)\n |-- avg_mon_Roll_Advert: double (nullable = false)\n |-- avg_mon_Save_Settings: double (nullable = false)\n |-- avg_mon_Settings: double (nullable = false)\n |-- avg_mon_Submit_Downgrade: double (nullable = false)\n |-- avg_mon_Submit_Registration: double (nullable = false)\n |-- avg_mon_Submit_Upgrade: double (nullable = false)\n |-- avg_mon_Thumbs_Down: double (nullable = false)\n |-- avg_mon_Thumbs_Up: double (nullable = false)\n |-- avg_mon_Upgrade: double (nullable = false)\n\n"}], "metadata": {"outputId": "cc3cc873-e4e0-4503-acc6-d9644d979e8d", "colab_type": "code", "id": "06AeBmq9N3jJ", "colab": {"base_uri": "https://localhost:8080/", "height": 867}}}, {"source": "### 3. Data Prep before ML", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "RI2dSXg5N3jN"}}, {"execution_count": 23, "cell_type": "code", "source": "# get list of categorical columns\nstr_cols = [item[0] for item in user_data_all.dtypes if item[1].startswith('string')]\n# remove userId since it's not required for modeling\nstr_cols.remove('userId')\n\n# get list of numerical columns\nnum_cols = [item[0] for item in user_data_all.dtypes if not item[1].startswith('string')]\n# remove label column since it's what we are predicting\nnum_cols.remove('label')", "outputs": [], "metadata": {}}, {"source": "Remove 'Cancel' and 'Cancellation_Confirmation' pages since we want to predict churn before we reach these pages.", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "3dSRSG0uEa0_"}}, {"execution_count": 25, "cell_type": "code", "source": "# remove 'Cancel' and 'Cancellation_Confirmation' pages since we want to predict churn before we reach these pages.\nnum_cols.remove('avg_daily_Cancel')\nnum_cols.remove('avg_daily_Cancellation_Confirmation')\n\nnum_cols.remove('avg_mon_Cancel')\nnum_cols.remove('avg_mon_Cancellation_Confirmation')", "outputs": [], "metadata": {"colab_type": "code", "id": "jo7lbUr9FLAv", "colab": {}}}, {"source": "#### 3.3. Transform data using Pipelines", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "-Rx-SMHON3jU"}}, {"source": "Transform dataset to get scaledFeatures and default PCA=10. PCA analysis will be performed later on 'scaledFeatures' to ascertain the best value for PCA features.", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "7VKwu-rFMh2G"}}, {"execution_count": null, "cell_type": "code", "source": "%%time\nuser_data_all_trans = transform_data(user_data_all, num_cols, str_cols, 10)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "CPU times: user 1.36 s, sys: 565 ms, total: 1.92 s\nWall time: 42min 14s\n"}], "metadata": {"outputId": "caeff124-2437-4a24-b1fb-942e004f33ba", "colab_type": "code", "id": "VB2hMNm7N3jU", "colab": {"base_uri": "https://localhost:8080/", "height": 52}}}, {"source": "#### 3.2 Imbalanced dataset", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "cpx8-WTJ3Xx_"}}, {"source": "A dataset is considered imbalanced if the ratio of one class is much higher than another class. In this dataset, the number of users who have churned are way less than number of active users. This poses a problem with classification models where all classes are not represented equally.", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "-Fkn4rAd1199"}}, {"execution_count": null, "cell_type": "code", "source": "major_df = user_data_all_trans.filter(user_data_all_trans.label == 0)\nminor_df = user_data_all_trans.filter(user_data_all_trans.label == 1)\nratio_df = int(major_df.count()/minor_df.count())\nprint(\"ratio: {}\".format(ratio_df))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "ratio: 3\n"}], "metadata": {"outputId": "0f0f39c6-a679-4c32-de3b-a64aa19cf757", "colab_type": "code", "id": "lciCoP5cN3ji", "colab": {"base_uri": "https://localhost:8080/", "height": 35}}}, {"source": "The data is heavily skewed towards label == 0 i.e. there are way more active users than churned users. Because the prediction classs is imbalanced, the ML models will be heavily skewed towards predicting label 0. In order to circumvent this situation, 'weights' column is created to provide more weight to the minority class. ", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "zbSrz-yC3ega"}}, {"execution_count": null, "cell_type": "code", "source": "# add new column weights\n# use user defined ratio field to provide appropriate weights to majority and minority class\nratio = 1/ratio_df\nuser_data_all_trans = user_data_all_trans.withColumn(\"weights\", when(user_data_all_trans.label == 1, ratio).otherwise(1-ratio))", "outputs": [], "metadata": {"colab_type": "code", "id": "NGkpHrl34G8e", "colab": {}}}, {"execution_count": null, "cell_type": "code", "source": "user_data_all_trans.head()", "outputs": [{"execution_count": 31, "output_type": "execute_result", "data": {"text/plain": "Row(features=DenseVector([0.0, 1.0, 4.0, 0.0, 19.0, 11.0, 1603889.5, 0.0, 1.75, 2.2727, 3.0, 1.0, 1.6, 2.4444, 0.0, 1.3636, 51.1, 0.0, 3.7, 1.0, 1.8, 1.0, 0.0, 1.0, 2.0625, 3.5333, 1.8, 0.0, 7.0, 12.5, 3.0, 1.5, 4.0, 22.0, 0.0, 7.5, 511.0, 0.0, 37.0, 1.0, 4.5, 1.0, 0.0, 1.0, 16.5, 26.5, 4.5]), scaledFeatures=DenseVector([0.0, 1.0, 0.04, 0.0, 0.6129, 0.0001, 0.5989, 0.0, 0.1346, 0.1748, 0.3333, 0.0667, 0.0038, 0.0004, 0.0, 0.1948, 0.1703, 0.0, 0.1, 0.2, 0.2571, 0.5, 0.0, 0.5, 0.2292, 0.1823, 0.2571, 0.0, 0.0511, 0.0698, 0.0451, 0.0033, 0.0003, 0.0001, 0.0, 0.0893, 0.0855, 0.0, 0.1462, 0.0769, 0.1125, 0.1667, 0.0, 0.1667, 0.2143, 0.0472, 0.2368]), pcaFeatures=DenseVector([-0.1748, 1.4498, 0.6747, 0.0235, -0.2046, 0.0358, -0.0505, -0.0181, 0.2288, -0.4635]), userId=u'1000280', gender=u'M', label=1, level=u'free', state=u' OH', device=u'Windows', days_since_reg=19, avg_mon_session_count=11.0, avg_mon_sess_duration=1603889.5, avg_daily_About=0.0, avg_daily_Add_Friend=1.75, avg_daily_Add_to_Playlist=2.272727272727273, avg_daily_Cancel=1.0, avg_daily_Cancellation_Confirmation=1.0, avg_daily_Downgrade=3.0, avg_daily_Error=1.0, avg_daily_Help=1.6, avg_daily_Home=2.4444444444444446, avg_daily_Login=0.0, avg_daily_Logout=1.3636363636363635, avg_daily_NextSong=51.1, avg_daily_Register=0.0, avg_daily_Roll_Advert=3.7, avg_daily_Save_Settings=1.0, avg_daily_Settings=1.8, avg_daily_Submit_Downgrade=1.0, avg_daily_Submit_Registration=0.0, avg_daily_Submit_Upgrade=1.0, avg_daily_Thumbs_Down=2.0625, avg_daily_Thumbs_Up=3.533333333333333, avg_daily_Upgrade=1.8, avg_mon_About=0.0, avg_mon_Add_Friend=7.0, avg_mon_Add_to_Playlist=12.5, avg_mon_Cancel=1.0, avg_mon_Cancellation_Confirmation=1.0, avg_mon_Downgrade=3.0, avg_mon_Error=1.5, avg_mon_Help=4.0, avg_mon_Home=22.0, avg_mon_Login=0.0, avg_mon_Logout=7.5, avg_mon_NextSong=511.0, avg_mon_Register=0.0, avg_mon_Roll_Advert=37.0, avg_mon_Save_Settings=1.0, avg_mon_Settings=4.5, avg_mon_Submit_Downgrade=1.0, avg_mon_Submit_Registration=0.0, avg_mon_Submit_Upgrade=1.0, avg_mon_Thumbs_Down=16.5, avg_mon_Thumbs_Up=26.5, avg_mon_Upgrade=4.5, weights=0)"}, "metadata": {}}], "metadata": {"outputId": "2f2ecdc2-1e3f-4131-81e3-5a935f56a5df", "colab_type": "code", "id": "K3Q8tAhFEBLj", "colab": {"base_uri": "https://localhost:8080/", "height": 55}}}, {"source": "'weights' column will be used in logistic regression becuase the model itself has an in-build parameter to handle imbalanced dataset.", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "gBqWNaGgDOv6"}}, {"source": "### 5. Split data into training and testing datasets", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "Ib9BLycBN3jo"}}, {"execution_count": null, "cell_type": "code", "source": "%%time\n# split data for training and testing datasets\ntrain, test = user_data_all_trans.randomSplit([0.7, 0.3], seed=42)\nprint(train.count())\nprint(test.count())", "outputs": [{"output_type": "stream", "name": "stdout", "text": "15530\n6748\nCPU times: user 522 ms, sys: 267 ms, total: 790 ms\nWall time: 17min 3s\n"}], "metadata": {"outputId": "06ac9da2-d475-4fdd-a74b-bfa3898f6356", "colab_type": "code", "id": "fNZ-9LvZ1FcI", "colab": {"base_uri": "https://localhost:8080/", "height": 87}}}, {"source": "#### 5.1 Save data before running ML models for later load.", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "xJo8yqT1STZ6"}}, {"execution_count": null, "cell_type": "code", "source": "# # save parquet file - save data\ntrain.write.parquet(\"gs://sparkify-bucket/data/train.parquet\")", "outputs": [], "metadata": {"colab_type": "code", "id": "pjn32zP1N3js", "colab": {}}}, {"execution_count": null, "cell_type": "code", "source": "# # save parquet file - save data\ntest.write.parquet(\"gs://sparkify-bucket/data/test.parquet\")", "outputs": [], "metadata": {"colab_type": "code", "id": "bqj9Pj7WN3jz", "colab": {}}}, {"execution_count": 4, "cell_type": "code", "source": "# using SQLContext to read parquet file\nfrom pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)\n\n# to read parquet file\ntrain = sqlContext.read.parquet(\"gs://sparkify-bucket/data/train.parquet\")\ntest = sqlContext.read.parquet(\"gs://sparkify-bucket/data/test.parquet\")", "outputs": [], "metadata": {"colab_type": "code", "id": "jhzqHmfON3j1", "colab": {}}}, {"source": "### 6. Run baseline models", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "dXyLt7rIN3j5"}}, {"source": "#### Instantiate model objects\nRun models with default parameters.", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "f-ujaqPEN3j5"}}, {"execution_count": 8, "cell_type": "code", "source": "# Logistic Regression\nlr_model = LogisticRegression(featuresCol = 'pcaFeatures', labelCol = 'label')\nlr_model_w = LogisticRegression(featuresCol = 'pcaFeatures', labelCol = 'label', weightCol='weights')\n\n# Gradient Boosting Trees (GBT)\ngbt_model = GBTClassifier(featuresCol = 'pcaFeatures', labelCol = 'label')\n\n# Decision Tree Classifier\ndt_model = DecisionTreeClassifier(featuresCol = 'pcaFeatures', labelCol = 'label')\n\n# RandomForest Classifier\nrf_model = RandomForestClassifier(featuresCol = 'pcaFeatures', labelCol = 'label')", "outputs": [], "metadata": {"colab_type": "code", "id": "biv0hTpQN3j6", "colab": {}}}, {"source": "#### F1 score for each model", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "7dNt781xN3j9"}}, {"source": "f1 score is a measure of accuracy that uses both precision and recall. \n\nf1 = 2*((precision*recall)/(precision+recall))\n\nSince we are dealing with imbalanced dataset where churned users much less than active users, it's best to use f1 score rather than accuracy which may provide high accuracy by just predicting majority class.", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "NssMtITlN3j9"}}, {"execution_count": null, "cell_type": "code", "source": "%%time\n# Logistic Regression\nlr_score_train, lr_score_test = model_testing(lr_model, train, test)\nprint(\"f1 score for Logistic Regression: train dataset {}, test dataset {}\".format(lr_score_train, lr_score_test))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "f1 score for Logistic Regression: train dataset 0.710391110612, test dataset 0.714728010953\nCPU times: user 1.14 s, sys: 530 ms, total: 1.67 s\nWall time: 27min 9s\n"}], "metadata": {"outputId": "062712f5-8199-4b85-9147-d1e1911ca487", "colab_type": "code", "id": "qdL4UuIzN3j9", "colab": {"base_uri": "https://localhost:8080/", "height": 69}}}, {"execution_count": null, "cell_type": "code", "source": "%%time\n# Logistic Regression with weights\nlr_score_train_w, lr_score_test_w = model_testing(lr_model_w, train, test)\nprint(\"f1 score for Logistic Regression: train dataset {}, test dataset {}\".format(lr_score_train_w, lr_score_test_w))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "f1 score for Logistic Regression: train dataset 0.673677046346, test dataset 0.677823686155\nCPU times: user 899 ms, sys: 387 ms, total: 1.29 s\nWall time: 26min 28s\n"}], "metadata": {"outputId": "204cd9e6-e835-42f3-8ba0-1eaf15c53b77", "colab_type": "code", "id": "DQ_QzkN5EIB1", "colab": {"base_uri": "https://localhost:8080/", "height": 69}}}, {"source": "We observe not a lot of diference between Logistic Regression using 'weights' and Logistic Regression without 'weights'.", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "ZF5_8-jCHlnL"}}, {"execution_count": null, "cell_type": "code", "source": "%%time\ngbt_score_train, gbt_score_test = model_testing(gbt_model, train, test)\nprint(\"f1 score for GBT Classifier: train dataset {}, test dataset {}\".format(gbt_score_train, gbt_score_test))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "f1 score for GBT Classifier: train dataset 0.773517400113, test dataset 0.769259875381\nCPU times: user 2.81 s, sys: 1.42 s, total: 4.23 s\nWall time: 27min 2s\n"}], "metadata": {"outputId": "92a32928-375a-444f-c639-f0196cb82321", "colab_type": "code", "id": "uTMN0Y31N3j_", "colab": {"base_uri": "https://localhost:8080/", "height": 69}}}, {"execution_count": null, "cell_type": "code", "source": "%%time\ndt_score_train, dt_score_test = model_testing(dt_model, train, test)\nprint(\"f1 score for Decision Tree Classifier: train dataset {}, test dataset {}\".format(dt_score_train, dt_score_test))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "f1 score for Decision Tree Classifier: train dataset 0.740949527496, test dataset 0.743873990648\nCPU times: user 1.33 s, sys: 531 ms, total: 1.86 s\nWall time: 33min 32s\n"}], "metadata": {"outputId": "2535a147-2037-4649-cf67-2d1bf118da1e", "colab_type": "code", "id": "frAtAQdjN3kB", "colab": {"base_uri": "https://localhost:8080/", "height": 69}}}, {"execution_count": null, "cell_type": "code", "source": "%%time\nrf_score_train, rf_score_test = model_testing(rf_model, train, test)\nprint(\"f1 score for Random Forest Classifier: train dataset {}, test dataset {}\".format(rf_score_train, rf_score_test))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "f1 score for Random Forest Classifier: train dataset 0.724383305188, test dataset 0.725493733818\nCPU times: user 1.19 s, sys: 552 ms, total: 1.74 s\nWall time: 33min 40s\n"}], "metadata": {"outputId": "5c7c30cc-24e3-4f2e-e7ee-d30462cd1566", "colab_type": "code", "id": "JzmGjfiBN3kD", "colab": {"base_uri": "https://localhost:8080/", "height": 69}}}, {"source": "Performance of classification models increased drastically as we ran these models on larger dataset.\nIn terms of performance, with just base settings, the GBT classifier outperformed the rest of the classifiers.", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "lA2F0Jx9ThwU"}}, {"source": "Now we can perform hyper parameter tuning to see if we can further improve the models.", "cell_type": "markdown", "metadata": {}}, {"source": "### 7. Parameter tuning", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "3LB_jmOxN3kE"}}, {"source": "#### Paramter tuning for Logistic Regression:", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "MrsYWO1a4Kob"}}, {"execution_count": null, "cell_type": "code", "source": "paramGrid = ParamGridBuilder()\\\n    .addGrid(lr_model.aggregationDepth,[2,5])\\\n    .addGrid(lr_model.elasticNetParam,[0.0, 0.5])\\\n    .addGrid(lr_model.maxIter,[10, 100])\\\n    .addGrid(lr_model.regParam,[0.01, 0.1]) \\\n    .build()", "outputs": [], "metadata": {"colab_type": "code", "id": "21et-WLeN3kF", "colab": {}}}, {"execution_count": null, "cell_type": "code", "source": "%%time\nscore_train_lr, score_test_lr, predict_train_lr, predict_test_lr, bestModel_lr = model_tuning(train, test, lr_model, paramGrid, 5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "CPU times: user 53.5 s, sys: 29 s, total: 1min 22s\nWall time: 2h 25min 8s\n"}], "metadata": {"outputId": "ae316af1-f22f-43de-942c-50dad92973d3", "colab_type": "code", "id": "1ZHVfPcpN3kI", "colab": {"base_uri": "https://localhost:8080/", "height": 52}}}, {"execution_count": null, "cell_type": "code", "source": "print(\"f1 train score: {}\".format(score_train_lr))\nprint(\"f1 test score: {}\".format(score_test_lr))\nprint(\"Best parameter for Aggregation depth: {}\".format(bestModel_lr._java_obj.getAggregationDepth()))\nprint(\"Best parameter for Elastic Net param: {}\".format(bestModel_lr._java_obj.getElasticNetParam()))\nprint(\"Best parameter for iterations: {}\".format(bestModel_lr._java_obj.getMaxIter()))\nprint(\"Best parameter for param: {}\".format(bestModel_lr._java_obj.getRegParam()))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "f1 train score: 0.711798861763\nf1 test score: 0.717922004117\nBest parameter for Aggregation depth: 2\nBest parameter for Elastic Net param: 0.0\nBest parameter for iterations: 10\nBest parameter for param: 0.01\n"}], "metadata": {"outputId": "0f07f5ce-f63e-48ff-93e4-0419153e8d4b", "colab_type": "code", "id": "Z4P0nB3RN3kK", "colab": {"base_uri": "https://localhost:8080/", "height": 139}}}, {"execution_count": null, "cell_type": "code", "source": "# check whether prediction consists of both labels.\npredict_test_lr.select(\"prediction\").dropDuplicates().show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------+\n|prediction|\n+----------+\n|       0.0|\n|       1.0|\n+----------+\n\n"}], "metadata": {"outputId": "ecec0ebe-b275-4cb0-c21e-5417a491bdc5", "colab_type": "code", "id": "thGROSc6pDMu", "colab": {"base_uri": "https://localhost:8080/", "height": 121}}}, {"execution_count": null, "cell_type": "code", "source": "predict_test_lr.select(\"userId\", \"label\", \"prediction\").show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-------+-----+----------+\n| userId|label|prediction|\n+-------+-----+----------+\n|1506897|    0|       0.0|\n|1553683|    0|       0.0|\n|1617595|    1|       0.0|\n|1804292|    0|       0.0|\n|1532306|    0|       0.0|\n|1744249|    0|       0.0|\n|1351489|    0|       0.0|\n|1190352|    0|       0.0|\n|1828442|    0|       0.0|\n|1059049|    0|       0.0|\n|1358765|    1|       0.0|\n|1200956|    0|       0.0|\n|1500901|    0|       0.0|\n|1880560|    0|       0.0|\n|1180406|    0|       0.0|\n|1612069|    0|       0.0|\n|1142513|    0|       0.0|\n|1699838|    0|       0.0|\n|1917123|    0|       0.0|\n|1927371|    0|       0.0|\n+-------+-----+----------+\nonly showing top 20 rows\n\n"}], "metadata": {"outputId": "f7ddc9e7-3251-4031-e45b-c78503646607", "colab_type": "code", "id": "HSTVC357N3kQ", "colab": {"base_uri": "https://localhost:8080/", "height": 468}}}, {"source": "We don't see any improvedment in Logistic regression test score.", "cell_type": "markdown", "metadata": {}}, {"source": "#### Parameter tuning for Random forest classifier:", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "7RMUPwpqVOoP"}}, {"execution_count": null, "cell_type": "code", "source": "# param grid for random forest classifier\nrf_paramGrid = ParamGridBuilder()\\\n              .addGrid(rf_model.maxDepth,[5, 10, 15])\\\n              .addGrid(rf_model.numTrees,[50, 100, 200])\\\n              .addGrid(rf_model.maxBins,[50, 100])\\\n              .build()", "outputs": [], "metadata": {"colab_type": "code", "id": "VTZvwK48TAuf", "colab": {}}}, {"execution_count": null, "cell_type": "code", "source": "%%time\nscore_train_rf, score_test_rf, predict_train_rf, predict_test_rf, bestModel_rf = model_tuning(train, test, rf_model, rf_paramGrid, 5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "CPU times: user 1min 8s, sys: 24.6 s, total: 1min 33s\nWall time: 7h 11min 19s\n"}], "metadata": {"outputId": "1ffb7344-7733-4f55-83f5-786ef3fd14f2", "colab_type": "code", "id": "4QjGiLGtVWu7", "colab": {"base_uri": "https://localhost:8080/", "height": 52}}}, {"execution_count": null, "cell_type": "code", "source": "print(\"f1 train score: {}\".format(score_train_rf))\nprint(\"f1 test score: {}\".format(score_test_rf))\nprint(\"Best parameter for max depth: {}\".format(bestModel_rf._java_obj.getMaxDepth()))\nprint(\"Best parameter for number of tress: {}\".format(bestModel_rf._java_obj.getNumTrees()))\nprint(\"Best parameter for number of bins: {}\".format(bestModel_rf._java_obj.getMaxBins()))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "f1 train score: 0.912099551257\nf1 test score: 0.83646658194\nBest parameter for max depth: 15\nBest parameter for number of tress: 200\nBest parameter for number of bins: 50\n"}], "metadata": {"outputId": "7c516652-eba0-4ec9-e35b-99b9baa46981", "colab_type": "code", "id": "kb5kOizUWBzl", "colab": {"base_uri": "https://localhost:8080/", "height": 104}}}, {"execution_count": null, "cell_type": "code", "source": "# check whether prediction consists of both labels.\npredict_test_rf.select(\"prediction\").dropDuplicates().show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------+\n|prediction|\n+----------+\n|       0.0|\n|       1.0|\n+----------+\n\n"}], "metadata": {"outputId": "19166991-ecce-44fc-9bef-06e1611b3485", "colab_type": "code", "id": "sEw-TUDkhJIQ", "colab": {"base_uri": "https://localhost:8080/", "height": 121}}}, {"source": "There is a considerable in crease in test score post parameter tuning. A f1 score of 0.83 is pretty good. It is not too high to suggest overfitting. Also, the prediction label includes both majority and minority classes.", "cell_type": "markdown", "metadata": {}}, {"source": "#### Parameter tuning for Decision Tree classifier:", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "V1Crq8U0GNAa"}}, {"execution_count": null, "cell_type": "code", "source": "# param grid for random forest classifier\ndt_paramGrid = ParamGridBuilder()\\\n              .addGrid(dt_model.maxDepth,[5, 10, 15])\\\n              .addGrid(dt_model.maxBins,[32, 50, 100])\\\n              .build()", "outputs": [], "metadata": {"colab_type": "code", "id": "ZZvTug0uGMYh", "colab": {}}}, {"execution_count": null, "cell_type": "code", "source": "%%time\nscore_train_dt, score_test_dt, predict_train_dt, predict_test_dt, bestModel_dt = model_tuning(train, test, dt_model, dt_paramGrid, 5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "CPU times: user 29.5 s, sys: 12 s, total: 41.5 s\nWall time: 2h 13min 20s\n"}], "metadata": {"colab_type": "code", "id": "hRcPlcnChimn", "colab": {}}}, {"execution_count": null, "cell_type": "code", "source": "print(\"f1 train score: {}\".format(score_train_dt))\nprint(\"f1 test score: {}\".format(score_test_dt))\nprint(\"Best parameter for max depth: {}\".format(bestModel_dt._java_obj.getMaxDepth()))\nprint(\"Best parameter for number of bins: {}\".format(bestModel_dt._java_obj.getMaxBins()))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "f1 train score: 0.903062864395\nf1 test score: 0.799080156163\nBest parameter for max depth: 15\nBest parameter for number of bins: 32\n"}], "metadata": {"colab_type": "code", "id": "9l0Fxq8wGaoP", "colab": {}}}, {"execution_count": null, "cell_type": "code", "source": "# check whether prediction consists of both labels.\npredict_test_dt.select(\"prediction\").dropDuplicates().show()", "outputs": [], "metadata": {"colab_type": "code", "id": "DVF616WAGckL", "colab": {}}}, {"source": "The Decision Tree classifier also improved a bit from 0.74 to 0.79.", "cell_type": "markdown", "metadata": {}}, {"source": "#### Parameter tuning for GBT classifier:", "cell_type": "markdown", "metadata": {"colab_type": "text", "id": "EDZVCMybITUj"}}, {"execution_count": 9, "cell_type": "code", "source": "# param grid for random forest classifier\ngbt_paramGrid = ParamGridBuilder()\\\n                .addGrid(gbt_model.maxDepth,[10, 15])\\\n                .addGrid(gbt_model.maxBins,[50, 100])\\\n                .build()\n            \n                #.addGrid(gbt_model.maxIter,[20, 50, 100])\\", "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%time\nscore_train_gbt, score_test_gbt, predict_train_gbt, predict_test_gbt, bestModel_gbt = model_tuning(train, test, gbt_model, gbt_paramGrid, 5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "CPU times: user 2.83 s, sys: 559 ms, total: 3.39 s\nWall time: 36min 36s\n"}], "metadata": {}}, {"execution_count": 14, "cell_type": "code", "source": "print(\"f1 score on train dataset: {}\".format(score_train_gbt))\nprint(\"f1 score on test dataset: {}\".format(score_test_gbt))\nprint(\"Best parameter for max depth: {}\".format(bestModel_gbt._java_obj.getMaxDepth()))\nprint(\"Best parameter for number of bins: {}\".format(bestModel_gbt._java_obj.getMaxBins()))\n#print(\"Best parameter for max iterations: {}\".format(bestModel_dt._java_obj.getMaxIter()))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "f1 score on train dataset: 0.936469868395\nf1 score on test dataset: 0.824570722945\nBest parameter for max depth: 10\nBest parameter for number of bins: 50\n"}], "metadata": {}}, {"execution_count": 16, "cell_type": "code", "source": "# check whether prediction consists of both labels.\npredict_test_gbt.select(\"prediction\").dropDuplicates().show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------+\n|prediction|\n+----------+\n|       0.0|\n|       1.0|\n+----------+\n\n"}], "metadata": {}}, {"source": "The GBT classifier also improved post tuning from 0.77 to 0.82.", "cell_type": "markdown", "metadata": {}}, {"source": "Overall, the Random Forest Classifier provides the best score at 0.8364.", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pyspark", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.14", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}, "colab": {"provenance": [], "machine_shape": "hm", "name": "sparkify_pipeline_cluster.ipynb"}}}